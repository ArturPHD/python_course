{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 16: Datasets and DataLoaders\n",
    "\n",
    "In the last lesson, we built a simple model from scratch. But to train any serious model, we need data. A lot of it.\n",
    "\n",
    "Today, we focus on the most important part of the machine learning pipeline: **the data**. We will learn how to load, prepare, and visualize a real-world dataset. We will **not** be building a model in this lesson; our only goal is to understand the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What are Datasets and DataLoaders?\n",
    "\n",
    "This is a core concept in PyTorch.\n",
    "\n",
    "1.  **`torch.utils.data.Dataset`**\n",
    "    * Think of this as a **textbook**. It's the complete collection of all your data (e.g., all 70,000 images and their labels). It knows how to access any specific item (e.g., `dataset[123]` would return the 123rd image and its label).\n",
    "\n",
    "2.  **`torch.utils.data.DataLoader`**\n",
    "    * Think of this as the **teacher** who uses the textbook. You don't read the entire textbook at once; the teacher gives you one chapter or one page at a time. \n",
    "    * The `DataLoader` wraps the `Dataset` and serves you the data in small, manageable **batches** (e.g., 64 images at a time). It also handles shuffling the data (so you don't memorize the order) and can even load data using multiple computer cores.\n",
    "\n",
    "We have put all this logic into a separate file, `data_loader.py`, so we can reuse it easily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The MNIST Dataset\n",
    "\n",
    "We will use the **MNIST** dataset. It's the \"Hello, World!\" of deep learning.\n",
    "\n",
    "* **What it is:** A collection of 70,000 28x28 pixel grayscale images of handwritten digits (0 through 9).\n",
    "* **Goal:** To eventually train a model that can look at one of these images and correctly classify which digit it is.\n",
    "\n",
    "### Data Format & Efficiency\n",
    "\n",
    "You might ask: \"Why don't we just have 70,000 PNG files in a folder?\"\n",
    "\n",
    "The dataset is stored in a few large, compressed binary files. This is *much* more efficient. Imagine if your dataset was 10 million images. If they were all tiny, individual `.png` files, your computer's hard drive would spend most of its time just *finding* and *opening* files, not reading them. This is called an **I/O (Input/Output) bottleneck**.\n",
    "\n",
    "By storing the data in a few large binary \"blobs\", the program can read millions of images in one continuous operation, which is thousands of times faster. \n",
    "\n",
    "Luckily for us, the `torchvision` library handles all the downloading and parsing of this binary format automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Split Data into Train, Validation, and Test?\n",
    "\n",
    "This is one of the most important concepts in all of machine learning. We *never* test our model on the same data it used for training. We use an analogy of a student studying for an exam:\n",
    "\n",
    "1.  **Training Set (The Homework):**\n",
    "    * This is the largest part of the data (e.g., ~54,000 images).\n",
    "    * The model looks at this data and its labels, and **learns by updating its parameters**.\n",
    "    * This is the *only* data the model ever learns from.\n",
    "\n",
    "2.  **Validation Set (The Mock/Practice Exam):**\n",
    "    * A smaller part of the data, held back from the model (e.g., ~6,000 images).\n",
    "    * The model **does not learn** from this. It only makes predictions.\n",
    "    * **We (the humans)** look at the model's score on this set *during* training to see if it's actually learning or just memorizing. If the score on the validation set stops improving, we know we should stop training.\n",
    "\n",
    "3.  **Test Set (The Final Exam):**\n",
    "    * A completely separate set of data (e.g., 10,000 images).\n",
    "    * The model and the developer have *never* seen this data before. We run the model on this set **only once** at the very end.\n",
    "    * This gives us the final, unbiased score of how well our model will perform in the real world on new, unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Loading and Visualizing the Data\n",
    "\n",
    "Now, let's use our `data_loader.py` file to load the data and see what it actually looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from data_loader import get_mnist_loaders\n",
    "\n",
    "# This will download the data (if not already present) and prepare the loaders\n",
    "# We set batch_size=64, meaning our DataLoader will give us 64 images at a time.\n",
    "train_loader, val_loader, test_loader = get_mnist_loaders(batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting a Batch\n",
    "\n",
    "Our `train_loader` is a Python iterable. Let's get one batch from it to see its properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get one batch of data\n",
    "data_iter = iter(train_loader)\n",
    "images, labels = next(data_iter)\n",
    "\n",
    "print(f\"Shape of one batch of images: {images.shape}\")\n",
    "print(f\"Shape of one batch of labels: {labels.shape}\")\n",
    "\n",
    "# The shape [64, 1, 28, 28] means:\n",
    "# [batch_size, color_channels, height, width]\n",
    "# It's '1' color channel because the images are grayscale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting a Single Digit\n",
    "\n",
    "Let's plot the very first image from the batch we just loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_image = images[0]\n",
    "first_label = labels[0]\n",
    "\n",
    "print(f\"Shape of one image: {first_image.shape}\")\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "# We use .squeeze() to remove the '1' color channel dimension (from [1, 28, 28] to [28, 28]), \n",
    "# so matplotlib can plot the 2D image.\n",
    "plt.imshow(first_image.squeeze(), cmap='gray')\n",
    "plt.title(f\"This image has the label: {first_label.item()}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "We have successfully:\n",
    "1.  Understood `Datasets` and `DataLoaders`.\n",
    "2.  Created a reusable `data_loader.py` file to handle all data preparation.\n",
    "3.  Visualized our input data to confirm it's correct.\n",
    "\n",
    "In the next lesson, we will import this *exact same* `data_loader.py` file and use the `train_loader` to train our first neural network."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}