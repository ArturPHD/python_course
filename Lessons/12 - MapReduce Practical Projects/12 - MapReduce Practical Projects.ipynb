{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 12: MapReduce Practical Projects\n",
    "\n",
    "Welcome to the practical part of our MapReduce module. In the previous lesson, you learned how to use our `FakeMapReduce` framework to solve specific, well-defined problems. Today, it's your turn to design and implement MapReduce solutions from scratch.\n",
    "\n",
    "This lesson contains a series of problems that you can solve individually or in groups. For each problem, you will need to:\n",
    "1.  Create a new data file for the input.\n",
    "2.  Create a new Python solver file (e.g., `log_analyzer.py`).\n",
    "3.  Write the `mapper` and `reducer` functions to solve the problem.\n",
    "4.  Use the `FakeMapReduce` framework to run your job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Reminder: The `FakeMapReduce` Workflow\n",
    "\n",
    "* **`mapper(line)`**: Your function must process a single line of input and `yield` one or more `(key, value)` pairs.\n",
    "* **`reducer(accumulator, next_value)`**: Your function takes two values associated with the same key and must return a single, combined value. Our framework applies this function iteratively.\n",
    "* **Framework**: You will import and use the `DataLoader` and `Job` classes from `FakeMapReduce.py` to run your solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 1: Log File Analyzer\n",
    "\n",
    "### Description\n",
    "You are given a server log file where each line represents a log entry. Each entry has a log level (`INFO`, `WARN`, `ERROR`), a service name, and a message. Your task is to count how many `ERROR` and `WARN` messages were produced by each service.\n",
    "\n",
    "### Data Format (`logs.txt`)\n",
    "Each line follows the format: `LEVEL - [Service Name] Message`\n",
    "\n",
    "**Example Data:**\n",
    "```\n",
    "INFO - [AuthService] User 'alice' logged in successfully\n",
    "WARN - [DatabaseService] Connection pool is reaching its limit\n",
    "ERROR - [PaymentService] Credit card transaction failed for user 'bob'\n",
    "INFO - [AuthService] User 'bob' updated profile\n",
    "ERROR - [DatabaseService] Query timed out\n",
    "ERROR - [AuthService] Failed login attempt for user 'eve'\n",
    "WARN - [DatabaseService] High latency detected on replica 2\n",
    "```\n",
    "\n",
    "### Task\n",
    "Write a MapReduce job that outputs the total count of `WARN` and `ERROR` logs for each service.\n",
    "\n",
    "**Expected Output:**\n",
    "```\n",
    "('AuthService', 'ERROR'): 1\n",
    "('DatabaseService', 'WARN'): 2\n",
    "('DatabaseService', 'ERROR'): 1\n",
    "('PaymentService', 'ERROR'): 1\n",
    "```\n",
    "\n",
    "### Hints\n",
    "\n",
    "* **Mapper**:\n",
    "    * Parse each line to extract the log level and the service name.\n",
    "    * If the level is `ERROR` or `WARN`, `yield` a key-value pair.\n",
    "    * What would be a good key to group the data correctly? A tuple `(service, level)` would be perfect.\n",
    "    * The value you emit should be `1`, just like in the word count example.\n",
    "\n",
    "* **Reducer**:\n",
    "    * Your reducer will receive two counts at a time for a given key.\n",
    "    * The logic should be identical to the word count reducer: simply sum the two values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 2: Average Score Calculator\n",
    "\n",
    "### Description\n",
    "You have a file containing student scores for different subjects. Your task is to calculate the average score for each subject.\n",
    "\n",
    "### Data Format (`scores.txt`)\n",
    "Each line follows the format: `StudentID,Subject,Score`\n",
    "\n",
    "**Example Data:**\n",
    "```\n",
    "101,Math,85\n",
    "102,Physics,92\n",
    "101,Physics,88\n",
    "103,Math,95\n",
    "102,Math,76\n",
    "103,Physics,90\n",
    "```\n",
    "\n",
    "### Task\n",
    "Write a MapReduce job that outputs the average score for each subject.\n",
    "\n",
    "**Expected Output:**\n",
    "```\n",
    "Math: 85.33\n",
    "Physics: 90.0\n",
    "```\n",
    "\n",
    "### Hints\n",
    "\n",
    "This is more complex because you can't directly average averages. To calculate an average, you need the **total sum** and the **total count**. Our pairwise reducer can't compute this in one step, so we need a clever trick.\n",
    "\n",
    "* **Mapper**:\n",
    "    * Parse the line to get the `Subject` and `Score`.\n",
    "    * The key should be the `Subject`.\n",
    "    * For the value, you need to emit both the score and a count of `1`. A tuple is perfect for this. `yield (subject, (score, 1))`\n",
    "\n",
    "* **Reducer (`reducer(accumulator, next_value)`)**:\n",
    "    * The `accumulator` will be a tuple like `(total_score_so_far, count_so_far)`.\n",
    "    * The `next_value` will also be a tuple `(score, 1)`.\n",
    "    * Your reducer must combine them by adding the scores and adding the counts: `return (accumulator[0] + next_value[0], accumulator[1] + next_value[1])`.\n",
    "\n",
    "* **Final Processing**:\n",
    "    * The final output from your MapReduce job for 'Math' will be `('Math', (256, 3))`. \n",
    "    * You will need to write a small formatting function *after* the job completes to loop through the results and calculate the final average (`total_score / count`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 3: Building an Inverted Index\n",
    "\n",
    "### Description\n",
    "An inverted index is a core component of a search engine. It maps content, such as words, to its locations in a document or a set of documents. Your task is to build an inverted index for a small collection of documents, where each line in the input file is considered a separate document.\n",
    "\n",
    "### Data Format (`documents.txt`)\n",
    "Each line is a document. The line number can be used as the document ID.\n",
    "\n",
    "**Example Data:**\n",
    "```\n",
    "Line 1: the quick brown fox\n",
    "Line 2: the lazy brown dog\n",
    "Line 3: the quick fox jumps\n",
    "```\n",
    "\n",
    "### Task\n",
    "Write a MapReduce job that creates an inverted index. The output should be a word followed by a sorted list of unique document IDs (line numbers) where that word appears.\n",
    "\n",
    "**Expected Output:**\n",
    "```\n",
    "brown: [1, 2]\n",
    "dog: [2]\n",
    "fox: [1, 3]\n",
    "jumps: [3]\n",
    "lazy: [2]\n",
    "quick: [1, 3]\n",
    "the: [1, 2, 3]\n",
    "```\n",
    "\n",
    "### Hints\n",
    "\n",
    "* **Data Input**: Your `DataLoader` needs to be slightly modified, or you need to keep track of the line number. A simple way is to use `enumerate` when reading the file.\n",
    "    ```python\n",
    "    # In your main solver script\n",
    "    with open(input_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    # Now you can pass (line_number, line_content) to the mapper\n",
    "    ```\n",
    "    This means your `mapper` will need to accept two arguments: `mapper(line_number, line_content)`.\n",
    "\n",
    "* **Mapper `mapper(line_number, line_content)`**:\n",
    "    * For each word in `line_content`, `yield (word, [line_number])`.\n",
    "    * Note that you are yielding a list containing a single line number.\n",
    "\n",
    "* **Reducer `reducer(accumulator, next_value)`**:\n",
    "    * Both `accumulator` and `next_value` will be lists of line numbers.\n",
    "    * Your reducer should simply combine the two lists: `return accumulator + next_value`.\n",
    "\n",
    "* **Final Processing**:\n",
    "    * The final output for a word might be a list with duplicates, like `('the', [1, 2, 1, 3])`.\n",
    "    * Write a final formatting function that loops through the results, converts the list to a `set` to get unique values, and then converts it back to a sorted `list` for the final output."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
